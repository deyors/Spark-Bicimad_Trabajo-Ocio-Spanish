{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PRACTICA_3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lbRuUirzHsOc",
        "NiG6s3QHnZdw",
        "2iFR0HyBJ6px",
        "SI06oIpLrdyB",
        "Ll72l5naCBSh",
        "1g-y7Y0NoNbb",
        "vH1eCfiWqt3G"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbRuUirzHsOc",
        "colab_type": "text"
      },
      "source": [
        "# LO BASICO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPvbxZvoHvIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!pip install pyspark\n",
        "import pandas as pd #librería de análisis de datos con buenas funciones para manejar tablas\n",
        "from tabulate import tabulate\n",
        "from pyspark import SparkContext\n",
        "import json\n",
        "from datetime import date\n",
        "import folium\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebMfCP8McUXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') #da acceso al Google Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiG6s3QHnZdw",
        "colab_type": "text"
      },
      "source": [
        "# EJECUTAR PRIMERO PARA VER EL PROGRAMA POR PASOS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYa8I0TYnhOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sc = SparkContext()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkNA1Z_1nikc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! wget -N wild.mat.ucm.es/tmp/sample_10e4.json\n",
        "rdd_bruto = sc.textFile(\"sample_10e4.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-y-O42ynjME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sc.stop() # Ejecutar solo si se desea parar manualmente el objeto SparkContext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iFR0HyBJ6px",
        "colab_type": "text"
      },
      "source": [
        "# ***PASO 1:*** Conseguir RDD: {\"id\": .. ; \"edad\": .. ; \"tipo\": .. ; \"viajes\" : [(fecha1,origen1,destino1),...] }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP6DnrSoSsx_",
        "colab_type": "text"
      },
      "source": [
        "Los ***pasos*** incluyen ***comandos*** que muestran ***pequeños fragmentos de la RDD*** con el fin de ***apreciar mejor su funcionamiento***. Estos comandos sacrifican tiempo de computación y no estarán incluidos en el comando final, así que se aconseja utilizar esta explicación con ***archivos no muy grandes*** (hasta 500mb). \n",
        "\n",
        "Se presenta el ***uso por pasos para archivos únicos***. El sistema para utilizar más archivos es análogo a utilizar uno y se implementará en el programa final."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6NbLbHh66Kg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "2110f958-9e21-4db3-a2bf-4114ed864f29"
      },
      "source": [
        "\"\"\"\n",
        "Función que dado un dato tipo \"2017-04-01T01:00:00.000+0200\" devuelve una \n",
        "tupla (X,Y) donde X es \"ES\" o \"FS\" dependiendo de si es entresemana o fin de \n",
        "semana, e Y es el intervalo asignado a cada hora.\n",
        "\n",
        "(Tabla que asigna intervalos de hora en el Guión de la Práctica)\n",
        "\"\"\"\n",
        "\n",
        "def fecha_tupla(string):\n",
        "  year = int(string[0:4])\n",
        "  month = int(string[5:7])\n",
        "  day = int(string[8:10])\n",
        "  hour = int(string[11:13])\n",
        "  dia_semana = date(year,month,day).weekday() #Con esto sacamos el día de la semana\n",
        "  es_o_fs = \"ES\"\n",
        "  intervalo_horario = 1\n",
        "  if dia_semana > 4: # 5 y 6 corresponde a sábado y domingo respectivamente\n",
        "    es_o_fs = \"FS\"\n",
        "  if hour >= 10 and hour < 13:\n",
        "    intervalo_horario = 2\n",
        "  elif hour >= 13 and hour < 16:\n",
        "    intervalo_horario = 3\n",
        "  elif hour >= 16 and hour < 21:\n",
        "    intervalo_horario = 4\n",
        "  elif hour >= 21 and hour < 23:\n",
        "    intervalo_horario = 5\n",
        "  elif hour >= 23 or (hour >= 00 and hour < 6):\n",
        "    intervalo_horario = 6\n",
        "  return (es_o_fs, intervalo_horario)\n",
        "\n",
        "\"\"\"\n",
        "La función mapper_1, dada una línea de la RDD original (en bruto), transforma\n",
        "sus datos en un par (K,V), donde:\n",
        "K = 'user_day_code edad tipo' (en adelante user_day_code = id)\n",
        "V = ( (\"ES\" o \"FS\", intervalo_horas) , estacion_origen , estacion_destino))\n",
        "\n",
        "Este mapeo (con una consiguiente agrupación) formará los elementos de RDD_1 y \n",
        "y ayudará a agrupar los viajes que hace un mismo usuario en un día. \n",
        "\"\"\"\n",
        "def mapper_1(line): #acepta lineas del diccionario original\n",
        "  data = json.loads(line)\n",
        "  usuario = data['user_day_code']\n",
        "  edad = str(data['ageRange'])\n",
        "  tipo = str(data['user_type'])\n",
        "  fecha = data['unplug_hourTime']['$date']\n",
        "  tupla_fecha = fecha_tupla(fecha)\n",
        "  origen = data['idunplug_station']\n",
        "  destino = data['idplug_station']\n",
        "  clave = usuario + \" \" + edad + \" \" + tipo \n",
        "  valor = (tupla_fecha, origen, destino)\n",
        "  return (clave, valor)\n",
        "\n",
        "\"Cargamos la rdd_1:\"\n",
        "\n",
        "rdd_1 = rdd_bruto.map(mapper_1).groupByKey()\n",
        "#formato RDD_1: ('id edad tipo', [((\"ES\",1),90,163), ((\"FS\",3),20,165), ...])\n",
        "print(\"----------------------\")\n",
        "print(\"RDD 1 cargado con éxito\")\n",
        "print(\"Muestra RDD 1:\")\n",
        "rdd_1.persist()\n",
        "print(rdd_1.first())\n",
        "print(\"----------------------\")\n",
        "\n",
        "\"\"\"\n",
        "La función mapper_2 toma las líneas de RDD_1 para transformarlas en diccionarios\n",
        "con la información que aparece en el objetivo del Paso 1:\n",
        "{\"id\": .. ; \"edad\": .. ; \"tipo\": .. ; \"viajes\" : [(fecha1,origen1,destino1),...]}\n",
        "\n",
        "La RDD que recogerá toda esta información será rdd_2. \n",
        "\"\"\"\n",
        "def mapper_2(line): # acepta lineas de pares ('id edad tipo', (ES, origen, destino))\n",
        "  clave = line[0]\n",
        "  lista_claves = clave.split()\n",
        "  lista_valores = []\n",
        "  for elementos in line[1]:\n",
        "    lista_valores.append(elementos)\n",
        "  dicc_final = dict(id=lista_claves[0],edad=int(lista_claves[1]),tipo=int(lista_claves[2]),viajes=lista_valores) \n",
        "  return dicc_final\n",
        "\n",
        "rdd_2 = rdd_1.map(mapper_2)\n",
        "print(\"RDD 2 cargado con éxito\")\n",
        "print(\"Muestra RDD 2:\")\n",
        "rdd_2.persist()\n",
        "print(rdd_2.first())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------\n",
            "RDD 1 cargado con éxito\n",
            "Muestra RDD 1:\n",
            "('e4d55deb9ac172a8d8f5f0a32599815bd51b7c8760d67e42b11adf7c0829341b 0 1', <pyspark.resultiterable.ResultIterable object at 0x7f2d0d35e128>)\n",
            "----------------------\n",
            "RDD 2 cargado con éxito\n",
            "Muestra RDD 2:\n",
            "{'id': 'e4d55deb9ac172a8d8f5f0a32599815bd51b7c8760d67e42b11adf7c0829341b', 'edad': 0, 'tipo': 1, 'viajes': [(('FS', 6), 90, 66)]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI06oIpLrdyB",
        "colab_type": "text"
      },
      "source": [
        "# ***PASO 2:*** CONSEGUIR RDD: {'id': .. , 'puntos': .. , 'uso_estaciones': ..}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ag3vjgAIB4xf",
        "colab_type": "text"
      },
      "source": [
        "El ***objetivo*** de este paso es ***conseguir una RDD*** formada por ***líneas de diccionarios*** donde ***a cada persona se le atribuya una puntuación*** en función de su ***edad***, ***tipo*** de usuario (anual u ocasional) y ***viajes*** (donde tomará importancia el día y horario de cada viaje, así como el número de ellos).\n",
        "\n",
        "En principio, ***cada parámetro*** (edad, tipo y viajes) otorgará \n",
        "***de 0 a 5 puntos*** a una persona, consiguiendo ***desde 0 puntos*** (usuario puramente\n",
        "*de ocio*) hasta un ***máximo de 15 puntos*** (usuario puramente *trabajador*).\n",
        "\n",
        "*Aclaración:* Para nosotros, un usuario *puramente de ocio o puramente trabajador* es aquel que *reúne todos los requisitos* que *consideramos imporantes a tener en cuenta para decidir una cosa u otra*. Esos requisitos se corresponderán en mayor o menor medida con la realidad, pero *en ningún caso supondrán que consideremos a ese cliente un cliente por ocio o trabajo con una seguridad total.*\n",
        "\n",
        "Tanto el ***parámetro edad*** como el del ***tipo*** de usuario pueden ***no estar presentes***, luego en el mapeo, si un ***parámetro falla*** se juzgará a la persona ***sobre 10 puntos***, y si fallan dos, ***sobre 5***. El *parámetro viajes siempre estará presente*.\n",
        "\n",
        "Una vez juzgada la puntuación de cada persona, teniendo en cuenta el número de parámetros que han fallado, se hará una ***media de puntuación***, que dejará a cada\n",
        "persona con una puntuacion ***entre 0*** (puramente de ocio) ***y 1*** (puramente trabajo). \n",
        "\n",
        "***Cada persona tiene asignado un uso de estaciones***, donde vienen las estaciones\n",
        "con las que la persona ***ha tenido contacto*** (*sin importar el número de veces\n",
        "que la haya usado*).\n",
        "\n",
        "Empezaremos definiendo las *funciones auxiliares*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGiprggCTKkc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Función que, dada una edad, devuelve los puntos correspondientes a esa edad\n",
        "atendiendo a las tablas del guión de la Práctica:\n",
        "\"\"\"\n",
        "def point_age(edad):\n",
        "  puntos = 0 # También vale para edad 6\n",
        "  if edad == 1 or edad == 2:\n",
        "    puntos = edad\n",
        "  elif edad == 3 or edad == 4:\n",
        "    puntos = edad + 1\n",
        "  elif edad == 5:\n",
        "    puntos = 3\n",
        "  return puntos\n",
        "\n",
        "\"\"\"\n",
        "Función que, dado un tipo de usuario (anual u ocasional), devuelve los puntos \n",
        "correspondientes al tipo atendiendo a las tablas del guión de la Práctica:\n",
        "\"\"\"\n",
        "\n",
        "def point_tipo(tipo):\n",
        "  puntos = 0\n",
        "  if tipo == 2:\n",
        "    puntos = 4\n",
        "  return puntos\n",
        "\n",
        "\"\"\"\n",
        "A continuación definiremos funciones que relacionarán el día de la semana e\n",
        "intervalos horarios introducidos con su puntuación correspondiente según el \n",
        "guión de la Práctica. \n",
        "\n",
        "1. Para un unico viaje:\n",
        "\n",
        "Funcion que dada una dupla de la forma (\"ES\" o \"FS\", intervalo_horas) devuelve \n",
        "la puntuacion de la misma en base al guión de la Práctica:\n",
        "\"\"\"\n",
        "\n",
        "def point_1viaje(es_o_fs,int_horas):\n",
        "  puntos = 0\n",
        "  if es_o_fs == 'ES':\n",
        "    if int_horas == 1:\n",
        "      puntos = 3.5\n",
        "    else:\n",
        "      puntos = 2.5\n",
        "  else:\n",
        "    if int_horas == 1:\n",
        "      puntos = 2.5\n",
        "    else:\n",
        "      puntos = 1\n",
        "  return puntos\n",
        "\n",
        "\"\"\"\n",
        "2. Para dos viajes:\n",
        "\n",
        "Función que dada una tupla tipo:\n",
        "(\"ES\" o \"FS\", intervalo_horario_viaje1,intervalo_horario_viaje2), devuelve \n",
        "la puntuacion de la misma en base al guión de la Práctica.\n",
        "\n",
        "Esto es posible gracias a la implementación de matrices, correspondientes \n",
        "a las tablas del guión de la Práctica, gracias a las cuales se obtiene la \n",
        "puntuación de una persona que realiza dos viajes en función del día \n",
        "y los intervalos horarios de cada viaje. \n",
        "\"\"\"\n",
        "\n",
        "M_ES =[[0,2,5,5,5,2.5],[2,0,2,3,4,2.5],[5,2,0,3,4,2.5],[5,3,3,0,3,3.5],[5,4,4,3,0,0],[1,2.5,2.5,3.5,0,0]] #entre semana\n",
        "M_FS = [[0,1,1.5,1.5,1.5,0],[1,0,0,1.5,1.5,1.5],[1.5,0,0,1,1.5,0],[1.5,1.5,1,0,1,0],[1.5,1.5,1.5,1,0,0],[0,1.5,0,0,0,0]] #fin de semana \n",
        "\n",
        "def point_2viajes(es_o_fs,viaje1_horario,viaje2_horario):\n",
        "  result = 0\n",
        "  if es_o_fs == 'ES':\n",
        "    result = M_ES[viaje1_horario-1][viaje2_horario-1]\n",
        "  elif es_o_fs == 'FS':\n",
        "    result = M_FS[viaje1_horario-1][viaje2_horario-1]\n",
        "  return result\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0iyRFvGTNnd",
        "colab_type": "text"
      },
      "source": [
        "Asumimos que si un cliente ***realiza 3 viajes al día o más***, es complicado designar\n",
        "***ante qué tipo de cliente estamos*** (incluso podría haber cogido la bicicleta por \n",
        "la mañana para trabajar y por la tarde para el ocio), así que en estos casos \n",
        "atribuiremos ***2,5 puntos en este nivel*** y ***utilizaremos los otros niveles*** para dar \n",
        "una conclusión más acertada.\n",
        "\n",
        "*Curiosidad:* En abril de 2017, según las pruebas de programación de nuestro grupo, *una persona batió el record mensual de usos diarios de BICIMAD* con un total de *33 usos en un día*. \n",
        "\n",
        "A continuación definimos el mapper que nos dará el RDD objetivo de este paso:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "248rnCczTRTv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "cbe693ea-6634-41e3-e786-146a678aba17"
      },
      "source": [
        "\"\"\"\n",
        "La función mapper_3 toma las líneas de RDD_2 para transformarlas en diccionarios\n",
        "con la información que aparece en el objetivo del Paso 1:\n",
        "{'id': .. , 'puntos': .. , \"uso_estaciones\": ..}\n",
        "\n",
        "La RDD que recogerá toda esta información será rdd_3. \n",
        "\"\"\"\n",
        "def mapper_3(line):\n",
        "  edad = line['edad']\n",
        "  tipo = line['tipo']\n",
        "  user = line['id']\n",
        "  lista_viajes = line['viajes'] #formato [((\"ES\",3), 2 , 127), ((\"ES\",5), 3, 29)), ...]\n",
        "  if edad == 0: #No hay información por edad\n",
        "    parametro_edad = 0\n",
        "    puntos_por_edad = 0 #Desactivamos el parámetro de la edad\n",
        "  else:\n",
        "    puntos_por_edad = point_age(edad) #Averiguamos los puntos correspondientes a la edad\n",
        "    parametro_edad = 1\n",
        "  if tipo == 0: #Análogo a la edad\n",
        "    puntos_por_tipo = 0\n",
        "    parametro_tipo = 0\n",
        "  else:\n",
        "    puntos_por_tipo = point_tipo(tipo)\n",
        "    parametro_tipo = 1\n",
        "\n",
        "  parametro_viajes = 1 #Siempre tendremos el parámetro viaje\n",
        "  numero_viajes = len(lista_viajes) #Depende de si tenemos 1 viaje, 2 o más \n",
        "\n",
        "  if numero_viajes == 1:\n",
        "    es_o_fs = lista_viajes[0][0][0]\n",
        "    int_horario = lista_viajes[0][0][1]\n",
        "    puntos_por_viajes = point_1viaje(es_o_fs,int_horario)\n",
        "\n",
        "  elif numero_viajes == 2:\n",
        "    es_o_fs = lista_viajes[0][0][0]\n",
        "    est1_horario = lista_viajes[0][0][1]\n",
        "    est2_horario = lista_viajes[1][0][1]\n",
        "    puntos_por_viajes = point_2viajes(es_o_fs,est1_horario,est2_horario)\n",
        "\n",
        "  else:\n",
        "    puntos_por_viajes = 2.5\n",
        "\n",
        "  puntos_id = (puntos_por_viajes + puntos_por_tipo + puntos_por_edad)/(5*(parametro_viajes+parametro_edad+parametro_tipo))\n",
        "  #Recuento de puntos por cada parámetro y media teniendo en cuenta cada parámetro\n",
        "  lista_estaciones_id = []\n",
        "  #Preparación de la clave \"uso_estaciones\":\n",
        "  for elem in lista_viajes:\n",
        "    if (elem[1] in lista_estaciones_id) == False:\n",
        "      lista_estaciones_id.append(elem[1])\n",
        "    if (elem[2] in lista_estaciones_id) == False:\n",
        "      lista_estaciones_id.append(elem[2])\n",
        "\n",
        "  lista_estaciones_id.sort() #Ordenamos la lista\n",
        "  #Definimos el formato del diccionario final\n",
        "  dic = dict(id=user,puntos=puntos_id, uso_estaciones=lista_estaciones_id)\n",
        "  return dic\n",
        "\n",
        "rdd_3 = rdd_2.map(mapper_3)\n",
        "print(\"RDD 3 cargado con éxito\")\n",
        "print(\"Muestra RDD 3:\")\n",
        "rdd_3.persist()\n",
        "print(rdd_3.first())\n",
        "print(\"----------------------\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RDD 3 cargado con éxito\n",
            "Muestra RDD 3:\n",
            "{'id': 'e4d55deb9ac172a8d8f5f0a32599815bd51b7c8760d67e42b11adf7c0829341b', 'puntos': 0.1, 'uso_estaciones': [66, 90]}\n",
            "----------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll72l5naCBSh",
        "colab_type": "text"
      },
      "source": [
        "# ***PASO 3:*** CONSEGUIR LISTA FINAL DE DICCIONARIOS DE LA FORMA: {'estacion': ... , 'media': ..., 'usos': ... , 'usos_ocio': ... , 'usos_trabajo': ...}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UygJ1Dq6CE1D",
        "colab_type": "text"
      },
      "source": [
        "Este es el paso ***más complicado*** de realizar y el que más recursos consume. En principio tardaba 6 minutos en ejecutarse en un archivo de 500mb (en el programa completo, por pasos hubiera tardado más). Ahora hemos conseguido que tarde 38 segundos. \n",
        "\n",
        " Cada persona tiene una ***puntuación*** y una ***lista de estaciones*** con las que ha tenido contacto. \n",
        "\n",
        "El ***objetivo*** de este paso es ***coger cada estación de esa lista*** y ***atribuirle la puntuación de las personas que la han utilizado***, así como otros parámetros.\n",
        "\n",
        "Si ***dos personas*** con distintas puntuaciones han utilizado la ***misma estación***, el objetivo es atribuirle a esa estacion la ***suma*** de las respectivas puntuaciones de cada persona y ***dividirla*** entre dos. Es lógico pensar que esto puede ***generalizarse*** a un número finito de personas y conseguir ***para cada estación su media de puntos***, así como su ***uso*** (*recuento del número de personas que han tenido contacto con ella*), su ***uso de ocio*** (*recuento del número de personas con una puntuación menor que 0.5 que han tenido contacto con ella*) y su ***uso de trabajo*** (*análogo al uso de ocio pero con personas con puntuación mayor de 0.5*)\n",
        "\n",
        "Hemos eliminado de 'usos_ocio' y 'usos_trabajo' a las ***personas con puntuación 0.5***. Estas personas sí que aparecen en 'usos', pero con 0.5 puntos asumimos que no podemos constatar con rigor un uso recreacional o laboral. \n",
        "\n",
        "***`Procedimiento del Paso 3:`***\n",
        "\n",
        "***`1)`*** **Cambiar el formato** *:{'id': .., 'puntos': .., 'uso_estaciones': [66, 90]}*\n",
        "\n",
        "**al formato** *:[('estacion23', {'puntos': ..., 'numero_personas': 1}),...]*\n",
        "\n",
        "Esta es una manera de conseguir que ***cada estación sea una clave***, pero como cada linea de la RDD anterior contiene una ***lista de estaciones***, cada linea de la nueva RDD con este formato será una ***lista***.\n",
        "\n",
        "*'numero_personas'* es siempre 1 en este formato, ya que la puntuación de la estación sólo ha dependido de la puntuación que le ha otorgado la persona. \n",
        "\n",
        "***`2)`*** ***Transformar una RDD de líneas en formato:***\n",
        "\n",
        "*línea 1 -> [('estacion23', {'puntos': ..., 'numero_personas': 1}),('estacion47', {'puntos': ..., 'numero_personas': 1}), ...]*\n",
        "\n",
        "***en una RDD de líneas en formato:***\n",
        "\n",
        "*línea 1 -> ('estacion23', {'puntos': ..., 'numero_personas': 1})*\n",
        "\n",
        "*línea 2 -> ('estacion47', {'puntos': ..., 'numero_personas': 1})*\n",
        "\n",
        "*línea 3 -> ...*\n",
        "\n",
        "Esto significa ***transformar una RDD de \"un tamaño\" en otra RDD de \"tamaño más grande\"***. Para este procedimiento seguiremos los siguientes ***pasos***: \n",
        "\n",
        "- Conseguir el ***número de elementos que tiene la lista más grande de todas las líneas de la RDD original***. Para esto aplicamos una pequeña ***reducción***. Este número será *n*. \n",
        "\n",
        "- ***Crear una lista de n RDD's*** donde ***cada línea de estas RDD's esté formada por el n-ésimo componente de la lista correspondiente a cada línea de la RDD original.*** Las RDD llegarán en algún momento a incluir lineas de tuplas vacías, ya que muchas listas de la RDD original tienen un tamaño pequeño. \n",
        "\n",
        "- ***Unir todas estas RDD's*** en una gran RDD formada, ahora sí, por los líneas de formato ('estacion23', {'puntos': ..., 'numero_personas': 1}) y tuplas en blanco. ***Filtrar*** después todas estas tuplas en blanco para expulsarlas. \n",
        "\n",
        "***`3)`*** ***Agrupar en la RDD de líneas en formato***:\n",
        "\n",
        "*('estacion23', {'puntos': ..., 'numero_personas': 1})*\n",
        "\n",
        "todos los elementos con ***estaciones iguales*** y ***devolver una RDD de líneas en formato***: \n",
        "\n",
        "*('estacion23', [{'puntos': 0.1 , 'numero_personas': 1}, {'puntos': 0.7 , 'numero_personas': 1}, ... ]*\n",
        "\n",
        "***`4)`*** ***Transformar la RDD anterior en una lista de diccionarios de la forma:***\n",
        "\n",
        "*{'estacion': ... , 'media': ..., 'usos': ... , 'usos_ocio': ... , 'usos_trabajo': ...}*\n",
        "\n",
        "***donde:***\n",
        "\n",
        "*'media'* = puntos en media de la estación (entre 0 y 1)\n",
        "\n",
        "*'usos'* = número de personas que han tenido contacto con la estación \n",
        "\n",
        "*'usos_ocio'* = número de personas con una puntuación menor de 0.5 que han tenido contacto con la estación \n",
        "\n",
        "*'usos_trabajo'* = número de personas con una puntuación mayor de 0.5 que han tenido contacto con la estación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjSS8EIdCCwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Apartado 1)\n",
        "\n",
        "def mapper_4(line): #parte de rdd_3, de formato {'id': .., 'puntos': .., 'uso_estaciones': [66, 90]}\n",
        "  puntos = line['puntos']\n",
        "  lista_estaciones = line['uso_estaciones']\n",
        "  lista_tupla_salida = []\n",
        "  for elem in lista_estaciones:\n",
        "    clave = 'estacion'+str(elem)\n",
        "    valor_dic = {'puntos': puntos, 'numero_personas':1}\n",
        "    lista_tupla_salida.append((clave,valor_dic))\n",
        "  return lista_tupla_salida #formato [('estacion23', {'puntos': ..., 'numero_personas': 1}),...]\n",
        "\n",
        "\n",
        "rdd_4 = rdd_3.map(mapper_4)\n",
        "print(\"RDD 4 cargado con éxito\")\n",
        "print(\"Muestra RDD 4:\") \n",
        "rdd_4.persist()\n",
        "print(rdd_4.first())\n",
        "print(\"----------------------\")\n",
        "\n",
        "#Apartado 2)\n",
        "\n",
        "def reducer_1(list_dic_1,list_dic_2):\n",
        "  if len(list_dic_1) > len(list_dic_2):\n",
        "    return list_dic_1\n",
        "  else:\n",
        "    return list_dic_2 #devuelve la lista de diccionarios más larga\n",
        "\n",
        "print(\"Iniciando REDUCCIÓN de apoyo...\")\n",
        "lista_dic_grande = rdd_4.reduce(reducer_1)\n",
        "\"\"\"\n",
        "La longitud de este diccionario es el máximo uso que le ha dado una persona al \n",
        "bicimad en un día, dentro de este archivo.\n",
        "\"\"\"\n",
        "print(\"Reducción de apoyo completada\")\n",
        "print(\"----------------------\")\n",
        "print(\"Iniciando separación de RDD's...\")\n",
        "print(\"Uniendo las RDD's por estación...\")\n",
        "\n",
        "#Ahora crearemos len(lista_dic_grande) RDD's distintas y las uniremos:\n",
        "\n",
        "def mapper_5(n, line):                      \n",
        "  longitud = len(line)\n",
        "  if n < len(line):\n",
        "    return line[n]\n",
        "  else:\n",
        "    tupla_vacia = ()\n",
        "    return tupla_vacia\n",
        "\"\"\"\n",
        "La función anterior coge elementos de la rdd_4 y se queda con su elemento \n",
        "número n-ésimo, si es que lo tiene. Si no lo tiene, devuelve una tupla vacía,\n",
        "\"\"\"\n",
        "\n",
        "rdd_5 = rdd_4.map(lambda x: mapper_5(0, x)) #mapeamos los primeros elementos\n",
        "i = 1\n",
        "while i < len(lista_dic_grande):\n",
        "  rdd_5 = rdd_5.union(rdd_4.map(lambda x: mapper_5(i, x))) #unimos todos los demás\n",
        "  i = i + 1\n",
        "\n",
        "#Apartado 3)\n",
        "\n",
        "rdd_6 = rdd_5.filter(lambda x: x != ()).groupByKey() \n",
        "#Con rdd_6 filtramos tuplas vacías y agrupamos todas las estaciones iguales. \n",
        "print(\"Unión completada con éxito en RDD 6\")\n",
        "print(\"Mostrando RDD 6...\")\n",
        "rdd_6.persist()\n",
        "muestra = rdd_6.first()\n",
        "print(\"Muestra de RDD 6:\")\n",
        "print(muestra)\n",
        "print(\"----------------------\")\n",
        "\n",
        "#Apartado 4)\n",
        "\n",
        "def mapper_6(line): #Cada linea es tipo ('estacion25', [{'puntos': ..., 'numero_personas: 1}, ... , ...])\n",
        "  clave = line[0]\n",
        "  lista_diccionarios = line[1]\n",
        "  dic_final = {'estacion': int(clave[8:]), 'media': 0, 'usos': 0, 'usos_ocio': 0, 'usos_trabajo': 0}\n",
        "  for elem in lista_diccionarios:\n",
        "    dic_final['media'] = dic_final['media'] + elem['puntos'] #primero calculamos los puntos totales\n",
        "    dic_final['usos'] = dic_final['usos'] + elem['numero_personas']\n",
        "    if elem['puntos'] < 0.5:\n",
        "      dic_final['usos_ocio'] = dic_final['usos_ocio'] + elem['numero_personas']\n",
        "    elif elem['puntos'] > 0.5:\n",
        "      dic_final['usos_trabajo'] = dic_final['usos_trabajo'] + elem['numero_personas']\n",
        "  #ahora calculamos la media de los puntos\n",
        "  dic_final['media'] = dic_final['media']/dic_final['usos']\n",
        "  return dic_final #devuelve {'estacion': ... , 'media': ... , 'usos': ... , 'usos_ocio': ... , 'usos_trabajo': ...}\n",
        "\n",
        "rdd_7 = rdd_6.map(mapper_6)\n",
        "print(\"RDD 7 cargada con éxito\")\n",
        "print(\"Muestra RDD 7:\")\n",
        "rdd_7.persist()\n",
        "print(rdd_7.first())\n",
        "print(\"----------------------\")\n",
        "\"\"\"\n",
        "Los elementos de rdd_7 son los diccionarios finales correspondientes a cada \n",
        "estación, y nos dan toda la información necesaria. \n",
        "Haciendo un collect de todos los elementos acabamos el paso 3.\n",
        "\"\"\"\n",
        "print(\"Cargando lista final...\")\n",
        "lista_final = rdd_7.collect()\n",
        "print(\"¡Lista final correctamente cargada!\")\n",
        "print(\"Mostrando los 10 primeros elementos de la lista final:\")\n",
        "for elem in lista_final[0:9]:\n",
        "  print(elem)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIlDxRWLTj5Y",
        "colab_type": "text"
      },
      "source": [
        "*Curiosidad:* Adjuntamos en el siguiente código *cómo fué el inicial paso 3 que programamos por primera vez*. En este paso *no sabíamos como crear RDD's \"más grandes\"* y decidimos hacer una *gran función de reducción* que *aceptara dos listas de diccionarios* y *buscara en cada diccionario de la primera lista diccionarios de la segunda lista* y *si las estaciones correspondientes fueran iguales entonces combinara esos diccionarios y los añadiera a una gran lista final.* Si no había estaciones iguales entre listas, simplemente se añadían los diccionarios como estaban en la lista final. \n",
        "\n",
        "Si bien la solución funcionaba, esta era mucho más lenta (6 minutos aprox. para 500mb). Aquí se puede ejecutar para hacerse una idea de cómo funcionaba:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bZjDEfiTrZW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "e05b81d8-ff85-4728-f729-5f8e1fadbeb9"
      },
      "source": [
        "def mapper_4(line): #parte de rdd_3, de formato {'id': .., 'puntos': .., 'uso_estaciones': [66, 90]}\n",
        "  puntos = line['puntos']\n",
        "  lista_estaciones = line['uso_estaciones']\n",
        "  lista_dic = []\n",
        "  for elem in lista_estaciones:\n",
        "    dic = {'estacion':elem , 'puntos': puntos, 'numero_personas':1}\n",
        "    lista_dic.append(dic)\n",
        "  return lista_dic\n",
        "\n",
        "\n",
        "print(\"----------------------\")\n",
        "rdd_4 = rdd_3.map(mapper_4)\n",
        "print(\"RDD de apoyo cargado con éxito\")\n",
        "print(\"Muestra RDD de apoyo:\")\n",
        "rdd_4.persist()\n",
        "print(rdd_4.first())\n",
        "print(\"----------------------\")\n",
        "\n",
        "def reducer_1(list_dic_1,list_dic_2): #parte de dos elementos de rdd_4, de formato [{\"estacion\": .. , \"puntos\": .. , \"numero_personas\": 1}, ...]\n",
        "  list_dic_total = list_dic_1 + list_dic_2\n",
        "  list_dic_final = []\n",
        "  while list_dic_total != []:\n",
        "    misma_estacion_que = 0\n",
        "    i = 1\n",
        "    while i<len(list_dic_total):\n",
        "      if list_dic_total[0]['estacion'] == list_dic_total[i]['estacion']:\n",
        "        misma_estacion_que = i\n",
        "      i = i + 1\n",
        "    if misma_estacion_que == 0:\n",
        "      list_dic_final.append(list_dic_total[0])\n",
        "      list_dic_total.pop(0)\n",
        "    else:\n",
        "      dic = {'estacion': list_dic_total[0]['estacion'], 'puntos': list_dic_total[0]['puntos']+list_dic_total[misma_estacion_que]['puntos'], 'numero_personas': list_dic_total[0]['numero_personas']+list_dic_total[misma_estacion_que]['numero_personas']}\n",
        "      list_dic_final.append(dic)\n",
        "      list_dic_total.pop(0)\n",
        "      list_dic_total.pop(misma_estacion_que-1)\n",
        "  return list_dic_final\n",
        "\n",
        "lista_dic_totales = rdd_4.reduce(reducer_1)\n",
        "print(\"Lista Diccionarios Finales DE APOYO cargados con éxito\")\n",
        "print(\"Muestra Lista Diccionales Finales DE APOYO\")\n",
        "print(lista_dic_totales[1])\n",
        "print(\"----------------------\")\n",
        "\n",
        "def dic_total_a_final(lista_dic_totales): #hace las medias\n",
        "  lista_dic_final = []\n",
        "  for elem in lista_dic_totales:\n",
        "    dic = {'estacion': elem['estacion'], 'media': elem['puntos']/elem['numero_personas']}\n",
        "    lista_dic_final.append(dic)\n",
        "  return lista_dic_final\n",
        "\n",
        "lista_dic_finales = dic_total_a_final(lista_dic_totales)\n",
        "\n",
        "print(\"Lista de Diccionarios FINALES cargados con éxito\")\n",
        "print(\"Muestra Lista Diccionarios FINALES\")\n",
        "print(lista_dic_finales[1])\n",
        "print(\"----------------------\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------\n",
            "RDD de apoyo cargado con éxito\n",
            "Muestra RDD de apoyo:\n",
            "[{'estacion': 66, 'puntos': 0.1, 'numero_personas': 1}, {'estacion': 90, 'puntos': 0.1, 'numero_personas': 1}]\n",
            "----------------------\n",
            "Lista Diccionarios Finales DE APOYO cargados con éxito\n",
            "Muestra Lista Diccionales Finales DE APOYO\n",
            "{'estacion': 90, 'puntos': 70.08333333333331, 'numero_personas': 266}\n",
            "----------------------\n",
            "Lista de Diccionarios FINALES cargados con éxito\n",
            "Muestra Lista Diccionarios FINALES\n",
            "{'estacion': 90, 'media': 0.2634711779448621}\n",
            "----------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyYNesm356QU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sc.stop() #parada manual del SparkContext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g-y7Y0NoNbb",
        "colab_type": "text"
      },
      "source": [
        "# ***`PROGRAMA ENTERO CON TODOS LOS PASOS JUNTOS`*** (ejecutar sólo lo básico antes, con SparkContext parado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qx0ppuBHT_I1",
        "colab_type": "text"
      },
      "source": [
        "Presentamos los algoritmos explicados con anterioridad de forma conjunta. Al ejecutar este programa podemos introducir los datos necesarios de forma interactiva y cargar los archivos que queramos. Estos archivos se unirán en una única RDD global que se procesará utilizando los pasos anteriores.\n",
        "\n",
        "Hemos quitado los comentarios en esta sección para no repetirnos y poder visualizar el código de forma conjunta. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw4cf7Wp7KxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Funciones auxiliares:\n",
        "\n",
        "def fecha_tupla(string):\n",
        "  year = int(string[0:4])\n",
        "  month = int(string[5:7])\n",
        "  day = int(string[8:10])\n",
        "  hour = int(string[11:13])\n",
        "  dia_semana = date(year,month,day).weekday() #Con esto sacamos el día de la semana\n",
        "  es_o_fs = \"ES\"\n",
        "  intervalo_horario = 1\n",
        "  if dia_semana > 4: # 5 y 6 corresponde a sábado y domingo respectivamente\n",
        "    es_o_fs = \"FS\"\n",
        "  if hour >= 10 and hour < 13:\n",
        "    intervalo_horario = 2\n",
        "  elif hour >= 13 and hour < 16:\n",
        "    intervalo_horario = 3\n",
        "  elif hour >= 16 and hour < 21:\n",
        "    intervalo_horario = 4\n",
        "  elif hour >= 21 and hour < 23:\n",
        "    intervalo_horario = 5\n",
        "  elif hour >= 23 or (hour >= 00 and hour < 6):\n",
        "    intervalo_horario = 6\n",
        "  return (es_o_fs, intervalo_horario)\n",
        "\n",
        "def point_age(edad):\n",
        "  puntos = 0 # También vale para edad 6\n",
        "  if edad == 1 or edad == 2:\n",
        "    puntos = edad\n",
        "  elif edad == 3 or edad == 4:\n",
        "    puntos = edad + 1\n",
        "  elif edad == 5:\n",
        "    puntos = 3\n",
        "  return puntos\n",
        "\n",
        "def point_tipo(tipo):\n",
        "  puntos = 0\n",
        "  if tipo == 2:\n",
        "    puntos = 4\n",
        "  return puntos  \n",
        "\n",
        "def point_1viaje(es_o_fs,int_horas):\n",
        "  puntos = 0\n",
        "  if es_o_fs == 'ES':\n",
        "    if int_horas == 1:\n",
        "      puntos = 3.5\n",
        "    else:\n",
        "      puntos = 2.5\n",
        "  else:\n",
        "    if int_horas == 1:\n",
        "      puntos = 2.5\n",
        "    else:\n",
        "      puntos = 1\n",
        "  return puntos\n",
        "\n",
        "M_ES =[[0,2,5,5,5,2.5],[2,0,2,3,4,2.5],[5,2,0,3,4,2.5],[5,3,3,0,3,3.5],[5,4,4,3,0,0],[1,2.5,2.5,3.5,0,0]] #entre semana\n",
        "M_FS = [[0,1,1.5,1.5,1.5,0],[1,0,0,1.5,1.5,1.5],[1.5,0,0,1,1.5,0],[1.5,1.5,1,0,1,0],[1.5,1.5,1.5,1,0,0],[0,1.5,0,0,0,0]] #fin de semana \n",
        "\n",
        "def point_2viajes(es_o_fs,viaje1_horario,viaje2_horario):\n",
        "  result = 0\n",
        "  if es_o_fs == 'ES':\n",
        "    result = M_ES[viaje1_horario-1][viaje2_horario-1]\n",
        "  elif es_o_fs == 'FS':\n",
        "    result = M_FS[viaje1_horario-1][viaje2_horario-1]\n",
        "  return result\n",
        "\n",
        "# Mappers y Reducers:\n",
        "\n",
        "def mapper_1(line): #acepta lineas del diccionario original\n",
        "  data = json.loads(line)\n",
        "  usuario = data['user_day_code']\n",
        "  edad = str(data['ageRange'])\n",
        "  tipo = str(data['user_type'])\n",
        "  fecha = data['unplug_hourTime']['$date']\n",
        "  tupla_fecha = fecha_tupla(fecha)\n",
        "  origen = data['idunplug_station']\n",
        "  destino = data['idplug_station']\n",
        "  clave = usuario + \" \" + edad + \" \" + tipo \n",
        "  valor = (tupla_fecha, origen, destino)\n",
        "  return (clave, valor)\n",
        "\n",
        "def mapper_2(line): # acepta lineas de pares ('id edad tipo', (ES, origen, destino))\n",
        "  clave = line[0]\n",
        "  lista_claves = clave.split()\n",
        "  lista_valores = []\n",
        "  for elementos in line[1]:\n",
        "    lista_valores.append(elementos)\n",
        "  dicc_final = dict(id=lista_claves[0],edad=int(lista_claves[1]),tipo=int(lista_claves[2]),viajes=lista_valores) \n",
        "  return dicc_final\n",
        "\n",
        "def mapper_3(line):\n",
        "  edad = line['edad']\n",
        "  tipo = line['tipo']\n",
        "  user = line['id']\n",
        "  lista_viajes = line['viajes'] #formato [((\"ES\",3), 2 , 127), ((\"ES\",5), 3, 29)), ...]\n",
        "  if edad == 0: #No hay información por edad\n",
        "    parametro_edad = 0\n",
        "    puntos_por_edad = 0 #Desactivamos el parámetro de la edad\n",
        "  else:\n",
        "    puntos_por_edad = point_age(edad) #Averiguamos los puntos correspondientes a la edad\n",
        "    parametro_edad = 1\n",
        "  if tipo == 0: #Análogo a la edad\n",
        "    puntos_por_tipo = 0\n",
        "    parametro_tipo = 0\n",
        "  else:\n",
        "    puntos_por_tipo = point_tipo(tipo)\n",
        "    parametro_tipo = 1\n",
        "\n",
        "  parametro_viajes = 1 #Siempre tendremos el parámetro viaje\n",
        "  numero_viajes = len(lista_viajes) #Depende de si tenemos 1 viaje, 2 o más \n",
        "\n",
        "  if numero_viajes == 1:\n",
        "    es_o_fs = lista_viajes[0][0][0]\n",
        "    int_horario = lista_viajes[0][0][1]\n",
        "    puntos_por_viajes = point_1viaje(es_o_fs,int_horario)\n",
        "\n",
        "  elif numero_viajes == 2:\n",
        "    es_o_fs = lista_viajes[0][0][0]\n",
        "    est1_horario = lista_viajes[0][0][1]\n",
        "    est2_horario = lista_viajes[1][0][1]\n",
        "    puntos_por_viajes = point_2viajes(es_o_fs,est1_horario,est2_horario)\n",
        "\n",
        "  else:\n",
        "    puntos_por_viajes = 2.5\n",
        "\n",
        "  puntos_id = (puntos_por_viajes + puntos_por_tipo + puntos_por_edad)/(5*(parametro_viajes+parametro_edad+parametro_tipo))\n",
        "  #Recuento de puntos por cada parámetro y media teniendo en cuenta cada parámetro\n",
        "  lista_estaciones_id = []\n",
        "  #Preparación de la clave \"uso_estaciones\":\n",
        "  for elem in lista_viajes:\n",
        "    if (elem[1] in lista_estaciones_id) == False:\n",
        "      lista_estaciones_id.append(elem[1])\n",
        "    if (elem[2] in lista_estaciones_id) == False:\n",
        "      lista_estaciones_id.append(elem[2])\n",
        "\n",
        "  lista_estaciones_id.sort() #Ordenamos la lista\n",
        "  #Definimos el formato del diccionario final\n",
        "  dic = dict(id=user,puntos=puntos_id, uso_estaciones=lista_estaciones_id)\n",
        "  return dic\n",
        "\n",
        "def mapper_4(line): #parte de rdd_3, de formato {'id': .., 'puntos': .., 'uso_estaciones': [66, 90]}\n",
        "  puntos = line['puntos']\n",
        "  lista_estaciones = line['uso_estaciones']\n",
        "  lista_tupla_salida = []\n",
        "  for elem in lista_estaciones:\n",
        "    clave = 'estacion'+str(elem)\n",
        "    valor_dic = {'puntos': puntos, 'numero_personas':1}\n",
        "    lista_tupla_salida.append((clave,valor_dic))\n",
        "  return lista_tupla_salida #formato [('estacion23', {'puntos': ..., 'numero_personas': 1}),...]\n",
        "\n",
        "def mapper_5(n, line):                      \n",
        "  longitud = len(line)\n",
        "  if n < len(line):\n",
        "    return line[n]\n",
        "  else:\n",
        "    tupla_vacia = ()\n",
        "    return tupla_vacia\n",
        "\n",
        "def mapper_6(line): #Cada linea es tipo ('estacion25', [{'puntos': ..., 'numero_personas: 1}, ... , ...])\n",
        "  clave = line[0]\n",
        "  lista_diccionarios = line[1]\n",
        "  dic_final = {'estacion': int(clave[8:]), 'media': 0, 'usos': 0, 'usos_ocio': 0, 'usos_trabajo': 0}\n",
        "  for elem in lista_diccionarios:\n",
        "    dic_final['media'] = dic_final['media'] + elem['puntos'] #primero calculamos los puntos totales\n",
        "    dic_final['usos'] = dic_final['usos'] + elem['numero_personas']\n",
        "    if elem['puntos'] < 0.5:\n",
        "      dic_final['usos_ocio'] = dic_final['usos_ocio'] + elem['numero_personas']\n",
        "    elif elem['puntos'] > 0.5:\n",
        "      dic_final['usos_trabajo'] = dic_final['usos_trabajo'] + elem['numero_personas']\n",
        "  #ahora calculamos la media de los puntos\n",
        "  dic_final['media'] = dic_final['media']/dic_final['usos']\n",
        "  return dic_final #devuelve {'estacion': ... , 'media': ... , 'usos': ... , 'usos_ocio': ... , 'usos_trabajo': ...}\n",
        "\n",
        "def reducer_1(list_dic_1,list_dic_2):\n",
        "  if len(list_dic_1) > len(list_dic_2):\n",
        "    return list_dic_1\n",
        "  else:\n",
        "    return list_dic_2 #devuelve la lista de diccionarios más larga"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oeX20BNoaKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(sc, lista_archivos):\n",
        "  rdd_bruto = sc.textFile(lista_archivos[0])\n",
        "  i = 1\n",
        "  if i < len(lista_archivos):\n",
        "    rdd_bruto = rdd_bruto.union(sc.textFile(lista_archivos[i]))\n",
        "    i = i + 1\n",
        "  rdd_1 = rdd_bruto.map(mapper_1).groupByKey() \n",
        "  #formato ('id edad tipo', [((\"ES\",2),90,163)), ((\"FS\",1),20,165)), ...])\n",
        "  print(\"----------------------\")\n",
        "  print(\"RDD 1 cargado con éxito\")\n",
        "\n",
        "  rdd_2 = rdd_1.map(mapper_2) \n",
        "  #formato {'id': ..., 'edad': 4, 'tipo': 1, 'viajes': [(\"ES\",2),90,163),((\"FS\",1), 20,165)), ... ]}\n",
        "  print(\"RDD 2 cargado con éxito\")\n",
        "\n",
        "  rdd_3 = rdd_2.map(mapper_3)\n",
        "  #formato {'id': ..., 'puntos': 0.4, 'uso_estaciones': [23, 129]}\n",
        "  print(\"RDD 3 cargado con éxito\")\n",
        "\n",
        "  rdd_4 = rdd_3.map(mapper_4)\n",
        "  print(\"RDD 4 cargado con éxito\")\n",
        "\n",
        "  print(\"Iniciando REDUCCIÓN de apoyo...\")\n",
        "  lista_dic_grande = rdd_4.reduce(reducer_1)\n",
        "  print(\"Reducción de apoyo completada\")\n",
        "  print(\"Iniciando separación de RDD's...\")\n",
        "  print(\"Uniendo las RDD's por estación...\")\n",
        "  rdd_5 = rdd_4.map(lambda x: mapper_5(0, x))\n",
        "  i = 1\n",
        "  while i < len(lista_dic_grande):\n",
        "    rdd_5 = rdd_5.union(rdd_4.map(lambda x: mapper_5(i, x)))\n",
        "    #unimos todos los demás\n",
        "    i = i + 1\n",
        "  print(\"RDD 5 cargado con éxito\")\n",
        "\n",
        "  rdd_6 = rdd_5.filter(lambda x: x != ()).groupByKey()\n",
        "  print(\"Unión completada con éxito en RDD 6\")\n",
        "\n",
        "  rdd_7 = rdd_6.map(mapper_6).filter(lambda x: x['estacion']<500)\n",
        "  #Para evitar errores en los archivos en bruto hemos filtrado la ultima RDD.\n",
        "  print(\"RDD 7 cargado con éxito\")\n",
        "  print(\"Guardando RDD como lista_trabajo_ocio.json...\")\n",
        "  \n",
        "  rdd_7 = rdd_7.coalesce(1, shuffle=True) #unimos el RDD en una sola partición\n",
        "\n",
        "  # Hacemos un map de todos los elementos del RDD a string\n",
        "  rdd_7 = rdd_7.map(json.dumps)\n",
        "\n",
        "  # Hacemos la reducción a una gran string separada por líneas con todos los datos\n",
        "  json_string = rdd_7.reduce(lambda x, y: x + \"\\n\" + y)\n",
        "\n",
        "  # Escribimos esta gran cadeana en un archivo\n",
        "  with open(\"lista_trabajo_ocio.json\", \"w\") as f:\n",
        "    f.write(json_string)\n",
        "\n",
        "  print(\"Archivo guardado satisfactoriamente.\")\n",
        "  print(\"Resultados publicados en el archivo lista_trabajo_ocio.json\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  print(\"Bienvenido a Spark BICIMAD TRABAJO/OCIO.\")\n",
        "  print(\"Programado por el Grupo 12 de la asignatura de Programación Paralela.\")\n",
        "  print(\"Este programa está diseñado para analizar los archivos de datos de \")\n",
        "  print(\"BICIMAD y dar resultados sobre su uso recreativo o laboral.\")\n",
        "  print(\"Para más información consulte el guión de la práctica.\")\n",
        "  print(\"--------------------------\")\n",
        "  print(\"Introduce la ruta del archivos que quieras analizar uno por uno. (no hacen falta las comillas)\")\n",
        "  print(\"Cuando hayas acabado de introducir rutas escribe EJECUTAR y se analiarán los archivos.\")\n",
        "  i = 0\n",
        "  j = 0\n",
        "  lista_archivos = []\n",
        "  archivo = input()\n",
        "  while j != 1:\n",
        "    if archivo == \"ejecutar\" or archivo == \"EJECUTAR\" or archivo[-5:] != \".json\":\n",
        "      print(\"No has introducido ningún archivo o tu archivo no es de la extension .json.\")\n",
        "      print(\"Por favor, introduce al menos un archivo con estas características.\")\n",
        "      archivo = input()\n",
        "    else:\n",
        "      j = 1\n",
        "      lista_archivos.append(archivo)\n",
        "  archivo = input()\n",
        "  while i != 1:\n",
        "    if archivo != \"ejecutar\" and archivo != \"EJECUTAR\":\n",
        "      if archivo[-5:] != \".json\":\n",
        "        print(\"Por favor, introduce archivos con extensión .json\")\n",
        "        archivo = input()\n",
        "      else:\n",
        "        lista_archivos.append(archivo)\n",
        "        archivo = input()\n",
        "    else:\n",
        "      i = 1\n",
        "  sc = SparkContext()\n",
        "  main(sc, lista_archivos)\n",
        "  sc.stop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH1eCfiWqt3G",
        "colab_type": "text"
      },
      "source": [
        "# OPCIONES DE VISUALIZACIÓN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGcxFzh1xVPq",
        "colab_type": "text"
      },
      "source": [
        "Dada una lista de ***diccionarios finales*** guardados en un archivo ***lista_trabajo_ocio.json***, devuelto por el anterior programa, las opciones de visualización que hemos implementado siguen un ***árbol de decisiones***:\n",
        "\n",
        "***1) Parámetro central del orden***: \n",
        "\n",
        "La visualización resultante puede *variar en función del parámetro que tome el protagonismo en el orden*: Número de estación, puntación media, número de usos totales, número de clientes por trabajo y número de clientes por ocio. \n",
        "\n",
        "***2) Orden del parámetro***:\n",
        "\n",
        "Cada parámetro elegido puede ser mostrado en *orden creciente o decreciente*.\n",
        "\n",
        "***3) Número de elementos:***\n",
        "\n",
        "Es posible que *solo se necesiten ciertos elementos en la tabla*. Se podrán elegir mostrar *toda la tabla* o sólo los *n primeros elementos.* \n",
        "\n",
        "- Una vez tomada una decisión se cargarán tres ***tipos de visualización diferentes:***\n",
        "\n",
        "***a)*** Se cargará una ***tabla*** en el *orden de la decisión tomada* donde se mostrarán de manera atractiva todos los datos elegidos. \n",
        "\n",
        "***b)*** Se cargará un ***mapa*** donde se ilustrarán *los primeros 10 elementos de dicha tabla*, con la *posicion*, *nombres* y *direcciones* de las estaciones. Esto es posible con la ayuda del *documento excel* que facilita la web de BICIMAD sobre coordenadas de estaciones. \n",
        "\n",
        "Si no se ha elegido una tabla con más de 10 elementos o no se pueden mostrar las coordenadas de todas las estaciones *el programa lo avisará* y *sólo mostrará los disponibles.* \n",
        "\n",
        "***c)*** Se cargará un ***gráfico de barras múltiples*** con información sobre el *uso*, *uso por trabajo* y *uso por ocio* de cada estación, en el orden fijado por la tabla. \n",
        "\n",
        "El ***proceso*** de este programa se detallará ***entre las líneas del código.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koioc9ESfn0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Funciones auxiliares:\n",
        "\n",
        "\"\"\"\n",
        "Esta función lee el excel de las coordenadas BICIMAD importado desde la web\n",
        "con un comando anterior y transforma los datos en una lista de diccionarios \n",
        "de formato {'id_est': ... , 'nombre_est': ..., 'dir_est': ... , 'lat_est': ... , 'lon_est': ...}\n",
        "donde cada elemento es:\n",
        "\n",
        "id_est = Identificador de la estación (id)\n",
        "nombre_est = Nombre de la estación (name)\n",
        "dir_est = Dirección de la estación (address)\n",
        "lat_est = Coordenada de la latitud de la estación (latitude)\n",
        "lon_est = Coordenada de la longitud de la estación (longitude)\n",
        "\"\"\"\n",
        "def import_coord_catalog(): \n",
        "\n",
        "    coords = pd.read_excel('2018_Julio_Bases_Bicimad_EMT.xlsx')\n",
        "    #Quitamos las columnas que no vamos a usar\n",
        "    coords = coords.drop(columns=['total_bases', 'number'])\n",
        "\n",
        "    #Preparamos la lista final de diccionarios\n",
        "    index = 0\n",
        "    lista_dic_coords = []\n",
        "    while index < len(coords.index):\n",
        "      id = coords.loc[index]['id']\n",
        "      nombre = coords.loc[index]['name']\n",
        "      dir = coords.loc[index]['address']\n",
        "      lat = coords.loc[index]['latitude']\n",
        "      lon = coords.loc[index]['longitude']\n",
        "      dic = {'id_est':id, 'nombre_est': nombre, 'dir_est': dir, 'lat_est': lat, 'lon_est': lon}\n",
        "      lista_dic_coords.append(dic)\n",
        "      index = index + 1\n",
        "\n",
        "    #Depuramos la lista de diccionarios: (no nos interesan coordenadas incompletas, id's repetidas ni direcciones erróneas)\n",
        "    lista_dic_coords_final = []\n",
        "    lista_id_ya_usada = [] \n",
        "    for elem in lista_dic_coords: \n",
        "      if elem['id_est'] not in lista_id_ya_usada: #Cualquier id repetida saldrá fuera de este condicional\n",
        "        #Quitamos elementos con latitudes y longitudes incoherentes\n",
        "        if (elem['lat_est'] < 41 and elem['lat_est'] > 40) and (elem['lon_est'] < -3 and elem['lon_est'] > -4): \n",
        "          #Todas las direcciones empiezan por nombres tipo Calle, Glorieta, etc. \n",
        "          #Las que no valen empiezan por comillas, etc.\n",
        "          if elem['dir_est'][0] in [\"A\", \"C\", \"P\", \"R\", \"G\"]: \n",
        "            lista_dic_coords_final.append(elem)\n",
        "            lista_id_ya_usada.append(elem['id_est'])\n",
        "          else:\n",
        "            #Si la dirección no es coherente la clasificamos como desconocida\n",
        "            elem['dir_est'] = \"Dirección desconocida\"\n",
        "            lista_dic_coords_final.append(elem)    \n",
        "            lista_id_ya_usada.append(elem['id_est'])\n",
        "\n",
        "    #Ordenamos la lista final por id para un resultado más limpio\n",
        "    lista_dic_coords_final.sort(key=(lambda x: x['id_est']))\n",
        "    return lista_dic_coords_final\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "v_table toma una lista formada por elementos cargados del último archivo \n",
        "sacado por el programa (lista_trabajo_ocio.json), una de las 5 opciones de\n",
        "parámetro, 2 de orden y n elementos sacados del programa principal detallados\n",
        "en la presentación del programa e imprime una tabla de estaciones con sus \n",
        "características, un gráfico de barras múltiples y el mapa correspondiente \n",
        "a la explicación de dicha presentación. \n",
        "\"\"\"\n",
        "\n",
        "def v_table(lista_tabla, opcion, orden, n): \n",
        "\n",
        "    #Ordenamos la lista de diccionarios según la opción deseada\n",
        "    if opcion == 1:\n",
        "      lista_tabla.sort(key=(lambda x: x['estacion']))\n",
        "    elif opcion == 2:\n",
        "      lista_tabla.sort(key=(lambda x: x['media']))\n",
        "    elif opcion == 3:\n",
        "      lista_tabla.sort(key=(lambda x: x['usos']))\n",
        "    elif opcion == 4:\n",
        "      lista_tabla.sort(key=(lambda x: x['usos_ocio']))\n",
        "    elif opcion == 5:\n",
        "      lista_tabla.sort(key=(lambda x: x['usos_trabajo']))\n",
        "\n",
        "    #Dependiendo del orden, tomamos n elementos de la lista ordenada o de la \n",
        "    #lista al revés y creamos un DataFrame para representarlo como tabla\n",
        "    if orden == 1:\n",
        "      lista_tabla = lista_tabla[0:n]\n",
        "      df = pd.DataFrame(lista_tabla)\n",
        "    elif orden == 2:\n",
        "      lista_tabla.reverse()\n",
        "      lista_tabla = lista_tabla[0:n]\n",
        "      df = pd.DataFrame(lista_tabla)\n",
        "\n",
        "    #Hacemos un recuento de las estaciones utilizadas, para la gráfica\n",
        "    #y el mapa\n",
        "    lista_estaciones = []\n",
        "    for elem in lista_tabla:\n",
        "      lista_estaciones.append(elem['estacion'])\n",
        "      elem.pop('estacion') #las pondremos en el eje X al representar la gráfica\n",
        "      elem.pop('media') #para la gráfica la media es demasiado pequeña en comparación con los demás valores\n",
        "\n",
        "    print(tabulate(df, headers='keys', showindex=False, tablefmt='psql'))\n",
        "\n",
        "    #Ahora sacamos el mapa correspondiente a las 10 estaciones superiores de la tabla \n",
        "    #Si no hay datos suficientes como para mostrar las 10 estaciones, mostramos las que se puedan\n",
        "    print(\"Mostrando mapa de las estaciones seleccionadas...\")\n",
        "    print(\" \")\n",
        "    #Cargamos la lista de diccionarios de coordenadas utilizando la función auxiliar anterior\n",
        "    lista_coord = import_coord_catalog()\n",
        "    #Preparamos el diccionario final con el que saldrán las estaciones que se van a representar\n",
        "    dic_final_estaciones_para_mapa = []\n",
        "    #Preparamos una lista de estaciones sin coordenada según nos las pida la lista de estaciones\n",
        "    estaciones_sin_coordenadas = []\n",
        "    i = 0\n",
        "    #Nos interesa que la longitud maxima de estaciones en el mapa sea 10, y que no se sobrepase\n",
        "    #la longitud de la lista de estaciones que hemos conseguido antes\n",
        "    while (len(dic_final_estaciones_para_mapa) < 10) and (i<len(lista_estaciones)):\n",
        "      #Cuando no exista el elemento deseado por la lista de estaciones este valor valdrá 1\n",
        "      hay_elem = 0\n",
        "      for dic_coord in lista_coord:\n",
        "        #Buscamos elementos del diccionario de coordenadas para cada índice de la lista de estaciones\n",
        "        if lista_estaciones[i] == dic_coord['id_est']:\n",
        "          dic_final_estaciones_para_mapa.append(dic_coord)\n",
        "          hay_elem = 1\n",
        "      if hay_elem == 0:\n",
        "        estaciones_sin_coordenadas.append(lista_estaciones[i])    \n",
        "      i = i + 1\n",
        "\n",
        "    if i < 9:\n",
        "      print(\"No hay suficientes datos en la tabla para representar en el mapa el top 10 de estaciones de la tabla.\")\n",
        "\n",
        "    #Preparamos una advertencia para las estaciones que no han podido ser identificadas\n",
        "    if estaciones_sin_coordenadas != []:\n",
        "      string_estaciones_no = \"\"\n",
        "      for elem in estaciones_sin_coordenadas:\n",
        "        if elem == estaciones_sin_coordenadas[0]:\n",
        "          string_estaciones_no = string_estaciones_no + str(elem)\n",
        "        elif elem == estaciones_sin_coordenadas[-1]:\n",
        "          string_estaciones_no = string_estaciones_no + \" y \" + str(elem)\n",
        "        else:\n",
        "          string_estaciones_no = string_estaciones_no + \", \" + str(elem)\n",
        "      print(\"No se han podido representar las estaciones \" + string_estaciones_no + \".\")\n",
        "   \n",
        "    print(\"Representando \"+ str(len(dic_final_estaciones_para_mapa)) + \" elementos:\")\n",
        "    \n",
        "    #Iniciamos el mapa y le añadimos marcadores para cada longitud de la lista definitiva de coordenadas\n",
        "    m = folium.Map(width=800,height=800,location=[40.428896, -3.702426], zoom_start=12.5)\n",
        "   \n",
        "    for elem in dic_final_estaciones_para_mapa:\n",
        "      folium.Marker([elem['lat_est'], elem['lon_est']], popup=elem['nombre_est'], tooltip=\"Estacion \" + str(elem['id_est']) + \": \" + elem['dir_est']).add_to(m)\n",
        "    display(m)\n",
        "\n",
        "    #Ahora sacamos el gráfico\n",
        "    print(\" \")\n",
        "    print(\"El gráfico correspondiente a esta tabla es:\")\n",
        "    print(\" \")\n",
        "    df2 = pd.DataFrame(lista_tabla, index=lista_estaciones)\n",
        "    df2.plot.bar()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  print(\" \")\n",
        "  print(\"Descargando Excel COORDENADAS de la Base de Datos de BICIMAD...\")\n",
        "  print(\" \")\n",
        "  ! wget -N https://datos.madrid.es/FWProjects/egob/Catalogo/Transporte/Bici/ficheros/2018_Julio_Bases_Bicimad_EMT.xlsx\n",
        "  print(\"Excel descargado. Nombrado como: 2018_Julio_Bases_Bicimad_EMT.xlsx\")\n",
        "  print(\" \")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy1zKptSLai8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Funcion principal:\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Esta función principal se encarga de cargar el último archivo sacado por el programa\n",
        "anterior (lista_trabajo_ocio.json) y de pedir las opciones necesarias para ordenar los \n",
        "elementos de la tabla de final según la presentación de este programa. \n",
        "\n",
        "Tras conseguir todos los datos necesarios hace una llamada a la función auxiliar v_table\n",
        "\"\"\"\n",
        "def main(sc):\n",
        "  #Busca el archivo lista_trabajo_ocio.json\n",
        "  print(\"Cargando lista_trabajo_ocio.json...\")\n",
        "\n",
        "  if os.path.isfile('/content/lista_trabajo_ocio.json'):\n",
        "      print('¡Archivo lista_trabajo_ocio.json encontrado!')\n",
        "  else:\n",
        "      print('ADVERTENCIA: El archivo lista_trabajo_ocio.json no se ha encontrado.')\n",
        "      print('Por favor, asegúrate de haber ejecutado el programa anterior.')\n",
        "      sc.stop()\n",
        "      sys.exit(\"Archivo lista_trabajo_ocio.json no encontrado\")\n",
        "  \n",
        "  \"\"\"\n",
        "  Carga la RDD correspondiente y calcula el número de elementos que tiene \n",
        "  utilizando una reducción. También carga los elementos y forma una lista\n",
        "  de diccionarios con las líneas de la RDD\n",
        "  \"\"\"\n",
        "  rdd_data = sc.textFile(\"/content/lista_trabajo_ocio.json\")\n",
        "  rdd_data = rdd_data.map(json.loads)\n",
        "  numero_filas = rdd_data.map(lambda x: 1).reduce(lambda x,y: x + y)\n",
        "  lista_tabla = rdd_data.collect()\n",
        "\n",
        "  print(\"RDD cargado con éxito.\")\n",
        "  print(\"--------------------\")\n",
        "  print(\"Selecciona con respecto a qué valor deseas ordenar la tabla:\")\n",
        "  print(\" \")\n",
        "  print(\"1 -> Según el número de la estación\")\n",
        "  print(\"2 -> Según la media de puntuación ocio/trabajo de la estación (0 = ocio, 1 = trabajo)\")\n",
        "  print(\"3 -> Según el número de usos por personas distintas de la estación\")\n",
        "  print(\"4 -> Según el número de usos por personas con puntuación menor que 0.5 (usos por ocio) de la estación\")\n",
        "  print(\"5 -> Según el número de usos por personas con puntuación mayor que 0.5 (usos por trabajo) de la estación\")\n",
        "  print(\" \")\n",
        "\n",
        "  opcion = input()\n",
        "\n",
        "  #Se asegura de mostrar fallos de lectura si los carácteres introducidos no \n",
        "  #corresponden a ninguna opción\n",
        "  if opcion not in [\"1\",\"2\",\"3\",\"4\",\"5\"]:\n",
        "    i = 0\n",
        "    while i != 1:\n",
        "      if opcion not in [\"1\",\"2\",\"3\",\"4\",\"5\"]:\n",
        "        print(\"No se reconoce el dígito marcado. Por favor, introduzca una opción de las anteriores:\")\n",
        "        print(\" \")\n",
        "        opcion = input()\n",
        "      else: \n",
        "        i = 1\n",
        "\n",
        "  opcion = int(opcion)\n",
        "\n",
        "  print(\" \")\n",
        "  print(\"Selecciona el orden según el cuál deseas ordenar la tabla:\")\n",
        "  print(\" \")\n",
        "  print(\"1 -> Orden creciente\")\n",
        "  print(\"2 -> Orden decreciente\")\n",
        "  print(\" \")\n",
        "\n",
        "  orden = input()\n",
        "\n",
        "  if orden not in [\"1\",\"2\"]:\n",
        "    i = 0\n",
        "    while i != 1:\n",
        "      if orden not in [\"1\",\"2\"]:\n",
        "        print(\"No se reconoce el dígito marcado. Por favor, introduzca una opción de las anteriores:\")\n",
        "        print(\" \")\n",
        "        orden = input()\n",
        "      else: \n",
        "        i = 1\n",
        "  orden = int(orden)\n",
        "\n",
        "  print(\" \")\n",
        "  print(\"Selecciona el número de filas que quieres mostrar:\")\n",
        "  print(\"T -> Todas las filas\")\n",
        "  print(\"(Número de filas que desees mostrar) -> N primeras filas (máximo \" + str(numero_filas) + \")\")\n",
        "  print(\" \")\n",
        "\n",
        "  numero_elementos = input()\n",
        "\n",
        "  j = 1\n",
        "  elementos_validos = [\"t\", \"T\"]\n",
        "  while j <= numero_filas:\n",
        "    elementos_validos.append(str(j))\n",
        "    j = j + 1\n",
        "\n",
        "  if numero_elementos not in elementos_validos:\n",
        "    i = 0\n",
        "    while i != 1:\n",
        "      if numero_elementos not in elementos_validos:\n",
        "        print(\"No se reconoce el comando marcado. Por favor, introduzca una opción de las anteriores:\")\n",
        "        print(\" \")\n",
        "        numero_elementos = input()\n",
        "      else: \n",
        "        i = 1\n",
        "\n",
        "  #Para cargar las diferentes impresiones según las opciones elegidas se crean diferentes strings\n",
        "  if numero_elementos in [\"t\", \"T\"]: \n",
        "    numero_elementos = numero_filas\n",
        "    p_numero = \"todos los\"\n",
        "\n",
        "  else:\n",
        "    if int(numero_elementos) == numero_filas:\n",
        "      p_numero = \"todos los\"\n",
        "      numero_elementos = int(numero_elementos)\n",
        "    else:\n",
        "      p_numero = numero_elementos\n",
        "      numero_elementos = int(numero_elementos)\n",
        "    \n",
        "  p_1 = \"Tabla ordenada en función \"\n",
        "\n",
        "  if opcion == 1:\n",
        "    p_opcion = \"del número de estaciones\"\n",
        "  elif opcion == 2:\n",
        "    p_opcion = \"de la media de las estaciones\"\n",
        "  elif opcion == 3:\n",
        "    p_opcion = \"del número de usos\"\n",
        "  elif opcion == 4:\n",
        "    p_opcion = \"del número de usos por ocio\"\n",
        "  elif opcion == 5:\n",
        "    p_opcion = \"del número de usos por trabajo\"\n",
        "\n",
        "  if orden == 1:\n",
        "    p_orden = \"creciente\"\n",
        "  elif orden == 2:\n",
        "    p_orden = \"decreciente\"\n",
        "\n",
        "  print(\" \")\n",
        "  print(p_1 + p_opcion + \" en orden \" + p_orden + \" mostrando \" + p_numero + \" elementos:\")\n",
        "  print(\" \")\n",
        "\n",
        "  #Finalmente se trasnfieren los datos recibidos a la función auxiliar\n",
        "  v_table(lista_tabla, opcion, orden, numero_elementos)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  print(\"Bienvenido a las opciones de visualización de Spark BICIMAD TRBAJO/OCIO\")\n",
        "  print(\"Asegúrate de haber ejecutado el programa anterior y de haber recibido el archivo lista_trabajo_ocio.json\")\n",
        "  print(\" \")\n",
        "  sc = SparkContext()\n",
        "  main(sc)\n",
        "  sc.stop()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}